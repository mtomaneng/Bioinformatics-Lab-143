---
title: "Class14"
author: "Matthew Tomaneng"
date: "5/17/2018"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Install DESeq2
```{r}
source("http://bioconductor.org/biocLite.R")
biocLite()

# For this class, you'll also need DESeq2:
biocLite("DESeq2")
```

Using Data from Another source
```{r}
counts <- read.csv("data/airway_scaledcounts.csv", stringsAsFactors = FALSE)
metadata <-  read.csv("data/airway_metadata.csv", stringsAsFactors = FALSE)
```

Check out the data
```{r}
head(counts)
```

```{r}
head(metadata)
```

Gene Analysis
```{r}
View(metadata)
```

```{r}
#Take the control data and form a bew table of only control
control <- metadata[metadata[,"dex"]=="control",]
control.mean <- rowSums( counts[ ,control$id] )/ length(control$id)
#put names back on the genes
names(control.mean) <- counts$ensgene
```
Q1: How would you make this code more robust?
A: the "4" is only for this data, just divide it by the length of the ID
```{r}
head(control)
head(control.mean)
```



Q2. Follow the same procedure for the treated samples (i.e. calculate the mean per gene accross drug treated samples and assign to a labeled vector called treated.mean)
```{r}
treated <- metadata[metadata[,"dex"] == "treated",]
treated.mean <- rowSums ( counts[, treated$id] )/ length(treated$id)
names(treated.mean) <- counts$ensgene
```

Check your work
```{r}
head(treated)
head(treated.mean)
```

Recombine Data
```{r}
meancounts <- data.frame(control.mean, treated.mean)
colSums(meancounts)
```

Q3. Create a scatter plot showing the mean of the treated samples against the mean of the control samples. Your plot should look something like the following.
```{r}
plot(control.mean, treated.mean)
#Why is there not that many points? Because they overlap each other
##WE use log of this data to spread it out better

```

LEts make the axis log
```{r}
plot(control.mean, treated.mean, log = "xy")
```

calculate log2foldchange, add it to meancounts data.frame
```{r}
meancounts$log2fc <- log2(meancounts[,"treated.mean"]/meancounts[,"control.mean"])
head(meancounts)
#NaN means 0/0 and no expression
#-inf means negative infinity which equals #/0
```

Filter Out nonusable data
```{r}
zero.vals <- which(meancounts[,1:2]==0, arr.ind=TRUE)
#arr.ind gives back a value corresponding to row and column and not just in a vector
#Gives a coordinate in the matrix

to.rm <- unique(zero.vals[,1])
mycounts <- meancounts[-to.rm,]
head(mycounts)
```

Finding which points were up or down regulated
```{r}
up.ind <- mycounts$log2fc > 2
down.ind <- mycounts$log2fc < (-2)
```

Q5. Using the up.ind and down.ind vectors above can you determine how many up and down regulated genes we have at the greater than 2 fc level?
```{r}
#print(up.ind)
#Want to find how many True's there are
sum(up.ind)
sum(down.ind)
```

##Adding annotation data
```{r}
anno <- read.csv("data/annotables_grch38.csv")
head(anno)
```

Q6. From consulting the help page for the merge() function can you set the by.x and by.y arguments appropriately to annotate our mycounts data.frame with all the available annotation data in your anno data.frame?
```{r}
?merge
results <- merge(mycounts, anno, by.y = "ensgene", by.x = "row.names")
results
```

Won't always have annotation file, so download the packages to do it
```{r}
#biocLite("AnnotationDbi")
#biocLite("org.Hs.eg.dbn")
library("AnnotationDbi")
library("org.Hs.eg.db")
```

Going to Add more details to the existing data
```{r}
columns(org.Hs.eg.db)
```

```{r}
mycounts$symbol <- mapIds(org.Hs.eg.db,
                     keys=row.names(mycounts),
                     column="SYMBOL",
                     keytype="ENSEMBL",
                     multiVals="first")
```

```{r}
head(mycounts)
```


##DESeq2 Analysis
Loading package
```{r}
#library("DESeq2")
```

```{R}
dds <- DESeqDataSetFromMatrix(countData=counts, 
                              colData=metadata, 
                              design=~dex, 
                              tidy=TRUE)
dds
```

```{r}
#results(dds)
#error because we never did calculations
dds <- DESeq(dds)
#we keep sending back the data back to orginal file, just how it works
res <- results(dds)
```

```{r}
res
#pvalue and padj added (p adjust)
##Will learn about this later
#basically with lots of data there is a high chance of getting a false positive
#padj makes corrects p value to realtive data
```

```{r}
summary(res)
```

Order summary
```{r}
resOrdered <- res[order(res$pvalue),]
resOrdered
```

Adjusting p-value
```{r}
resSig01 <- results(dds, alpha = .01)
resSig01$symbols <-  mapIds(org.Hs.eg.db,
                     keys=row.names(resSig01),
                     column="SYMBOL",
                     keytype="ENSEMBL",
                     multiVals="first")
res05 <- results(dds, alpha=0.05)
summary(resSig01)
```

A more generic view of this
```{r}
resSig05 <- subset(as.data.frame(res), padj < 0.05)
nrow(resSig05)
resSig01 <- subset(as.data.frame(res), padj < .01)
```

View the Results in order again
```{r}
ord <- order( resSig01$padj )
#View(res01[ord,])
head(resSig01[ord,])
```

Make a CSV file from the data
```{r}
write.csv(resSig01[ord,], "signif01_results.csv")
```

##Data Visualization

Plotting Counts
```{r}
i <- grep("CRISPLD2", resSig01$symbol)
resSig01[i,]
```

```{r}
rownames(resSig01[i,])
```








